{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1d13b48",
   "metadata": {},
   "source": [
    "# Multilabel Classification of Tiger Beetles Using Deep Learning\n",
    "\n",
    "This notebook implements taxonomic classification of tiger beetle specimens in the genus *Cicindela* using fastai and PyTorch. The approach uses a two-stage training strategy:\n",
    "\n",
    "1. **Single-label training**: Train a model to predict the most specific taxonomic level available (species or subspecies) as a single concatenated label\n",
    "2. **Multi-label transfer learning**: Transfer learned features to a multi-label model that can predict both species and subspecies separately\n",
    "\n",
    "This methodology allows the model to learn hierarchical taxonomic relationships while handling cases where only species-level identification is possible. The approach follows methodologies established in taxonomic classification literature.\n",
    "\n",
    "**Author**: B. de Medeiros, 2025\n",
    "\n",
    "## Setup and Dependencies\n",
    "\n",
    "Import required libraries and configure training parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "988173e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, gc\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from fastai.vision.all import *\n",
    "from fastai.distributed import *\n",
    "from accelerate import notebook_launcher\n",
    "from timm.loss import AsymmetricLossMultiLabel\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, auc, precision_score, recall_score\n",
    "from collections import defaultdict, Counter\n",
    "from IPython.display import display, HTML\n",
    "import torch\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "\n",
    "export_path = Path(\"exported_fastai_models\")\n",
    "batch_size = 8\n",
    "resize_dim = 448\n",
    "n_workers = 4\n",
    "p_memory = False\n",
    "p_workers = False\n",
    "arch = 'eva02_large_patch14_448.mim_m38m_ft_in22k_in1k'\n",
    "#arch = 'resnet18'\n",
    "\n",
    "os.makedirs(export_path, exist_ok=True)\n",
    "%matplotlib inline\n",
    "\n",
    "# Define the paths to your data\n",
    "train_path = Path(\"images/train\")\n",
    "valid_path = Path(\"images/valid\")\n",
    "test_path = Path(\"images/test\")\n",
    "\n",
    "# Function to create labels from directory names\n",
    "def extract_labels(dir_name):\n",
    "    \"\"\"\n",
    "    Extract both species and subspecies labels from directory names.\n",
    "    For example:\n",
    "    - abbreviata_var_baliensis -> ['abbreviata', 'abbreviata_var_baliensis']\n",
    "    - alba_ -> ['alba']\n",
    "    \"\"\"\n",
    "    parts = dir_name.rstrip('_').split('_')\n",
    "    species = parts[0]\n",
    "    \n",
    "    labels = [species]\n",
    "    if len(parts) > 1:\n",
    "        # Include the full name as a subspecies label\n",
    "        subspecies = '_'.join(parts)\n",
    "        labels.append(subspecies)\n",
    "    \n",
    "    return labels\n",
    "\n",
    "# Function to create a dataframe with file paths and labels\n",
    "def create_dataframe(data_path):\n",
    "    rows = []\n",
    "    \n",
    "    for dir_name in os.listdir(data_path):\n",
    "        # Skip any non-directory items or cache files\n",
    "        if not os.path.isdir(data_path/dir_name) or dir_name == 'labels.cache':\n",
    "            continue\n",
    "            \n",
    "        # Get the labels for this directory\n",
    "        labels = extract_labels(dir_name)\n",
    "        \n",
    "        # Get all image files in the directory\n",
    "        img_files = list(Path(data_path/dir_name).glob('*.*'))\n",
    "        for img_file in img_files:\n",
    "            if img_file.suffix.lower() in ['.jpg', '.jpeg', '.png']:\n",
    "                rows.append({\n",
    "                    'path': img_file,\n",
    "                    'labels': labels\n",
    "                })\n",
    "    \n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def remove_redundant_subspecies(df):\n",
    "    \"\"\"\n",
    "    Process the dataframe to remove redundant subspecies labels.\n",
    "    \n",
    "    A subspecies is considered redundant if:\n",
    "    1. All instances of a species that have a subspecies label have the SAME subspecies\n",
    "    2. The species always has a subspecies (no records with just the species)\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with a 'labels' column containing semicolon-separated labels\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with redundant subspecies labels removed\n",
    "    \"\"\"\n",
    "    # Create mappings to track species and their subspecies\n",
    "    species_to_subspecies = {}  # Map species to set of associated subspecies\n",
    "    species_counts = {}         # Count total occurrences of each species\n",
    "    species_with_subspecies = {}  # Count how often a species has a subspecies\n",
    "    \n",
    "    # Process each row to build the mappings\n",
    "    for _, row in df.iterrows():\n",
    "        labels = row['labels']\n",
    "        species = labels[0]\n",
    "        \n",
    "        # Update total species count\n",
    "        species_counts[species] = species_counts.get(species, 0) + 1\n",
    "        \n",
    "        # If there's a subspecies, track it\n",
    "        if len(labels) > 1:\n",
    "            subspecies = labels[1]\n",
    "            \n",
    "            # Update subspecies tracking\n",
    "            if species not in species_to_subspecies:\n",
    "                species_to_subspecies[species] = set()\n",
    "            species_to_subspecies[species].add(subspecies)\n",
    "            \n",
    "            # Update count of species with subspecies\n",
    "            species_with_subspecies[species] = species_with_subspecies.get(species, 0) + 1\n",
    "    \n",
    "    # Find truly redundant subspecies (single subspecies AND all instances have it)\n",
    "    redundant_subspecies = {}\n",
    "    for species, subspecies_set in species_to_subspecies.items():\n",
    "        # Check if this species only has one subspecies\n",
    "        if len(subspecies_set) == 1:\n",
    "            # Check if all instances of this species have a subspecies\n",
    "            if species_counts[species] == species_with_subspecies[species]:\n",
    "                redundant_subspecies[species] = next(iter(subspecies_set))\n",
    "    \n",
    "    # Process the dataframe to remove redundant subspecies\n",
    "    updated_df = df.copy()\n",
    "    \n",
    "    for idx, row in updated_df.iterrows():\n",
    "        labels = row['labels']\n",
    "        \n",
    "        if len(labels) > 1:\n",
    "            species = labels[0]\n",
    "            subspecies = labels[1]\n",
    "            \n",
    "            # If this is a redundant subspecies, remove it\n",
    "            if species in redundant_subspecies and subspecies == redundant_subspecies[species]:\n",
    "                updated_df.at[idx, 'labels'] = [species]\n",
    "    \n",
    "    # Print summary of removed redundant subspecies\n",
    "    if redundant_subspecies:\n",
    "        print(f\"Removed {len(redundant_subspecies)} redundant subspecies labels:\")\n",
    "        for species, subspecies in redundant_subspecies.items():\n",
    "            print(f\"  - {subspecies} (always associated with {species})\")\n",
    "    else:\n",
    "        print(\"No redundant subspecies labels found.\")\n",
    "        \n",
    "    return updated_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6215c48b",
   "metadata": {},
   "source": [
    "## Data Organization and Label Processing\n",
    "\n",
    "This section sets up the data processing pipeline:\n",
    "\n",
    "1. **Directory structure**: Images are organized in subdirectories named by taxonomic labels (e.g., \"repanda_repanda\", \"sexguttata\")\n",
    "2. **Label extraction**: The `extract_labels()` function creates hierarchical labels from directory names:\n",
    "   - Single names (e.g., \"sexguttata\") → species only: [\"sexguttata\"]  \n",
    "   - Compound names (e.g., \"repanda_repanda\") → species + subspecies: [\"repanda\", \"repanda_repanda\"]\n",
    "3. **Redundancy removal**: `remove_redundant_subspecies()` eliminates subspecies labels that provide no additional information beyond the species name\n",
    "4. **Data merging**: Training and validation sets are combined with an `is_valid` flag for splitting\n",
    "\n",
    "## Dataset Analysis and Statistics\n",
    "\n",
    "Analyze the dataset composition and class distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f2f6055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 8 redundant subspecies labels:\n",
      "  - princeps_ducalis (always associated with princeps)\n",
      "  - aurulenta_aurulenta (always associated with aurulenta)\n",
      "  - lacteola_lacteola (always associated with lacteola)\n",
      "  - roseiventris_mexicana (always associated with roseiventris)\n",
      "  - coerulea_nitida (always associated with coerulea)\n",
      "  - clypeata_clypeata (always associated with clypeata)\n",
      "  - varians_lecontei (always associated with varians)\n",
      "  - soluta_soluta (always associated with soluta)\n",
      "Total images: 6279\n",
      "Training images: 4883\n",
      "Validation images: 1396\n",
      "Total unique labels: 248\n",
      "Species labels: 141\n",
      "Subspecies labels: 107\n",
      "\n",
      "Top 10 most common labels:\n",
      "repanda             644\n",
      "punctulata          642\n",
      "repanda_repanda     461\n",
      "sexguttata          421\n",
      "formosa             355\n",
      "scutellaris         355\n",
      "oregona             343\n",
      "oregona_oregona     281\n",
      "ocellata            257\n",
      "formosa_generosa    245\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Bottom 10 least common labels:\n",
      "dysenterica                    1\n",
      "hydrophoba_atroreducta         1\n",
      "crespignyi                     1\n",
      "lugens_aphrodisia              1\n",
      "lacrymans                      1\n",
      "carthagena_colossea            1\n",
      "tranquebarica_parallelonota    1\n",
      "parowana_wallisi               1\n",
      "klugii                         1\n",
      "nigrocoerulea_bowditchi        1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample of extracted labels for verification:\n",
      "Path: 34_4_5_tray_04_spec_004_masked_whitebg.png, Labels: ['campestris', 'campestris_campestris']\n",
      "Path: 34_5_3_tray_08_spec_026_masked_whitebg.png, Labels: ['purpurea']\n",
      "Path: 34_4_10_tray_10_spec_008_masked_whitebg.png, Labels: ['hirticollis', 'hirticollis_shelfordi']\n",
      "Path: 34_5_8_tray_05_spec_027_masked_whitebg.png, Labels: ['tenuisignata']\n",
      "Path: 34_4_15_tray_04_spec_007_masked_whitebg.png, Labels: ['pulchra']\n",
      "\n",
      "Species with most images:\n",
      "repanda        1108\n",
      "punctulata      856\n",
      "scutellaris     710\n",
      "formosa         706\n",
      "oregona         676\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Species with fewest images:\n",
      "desertorum     1\n",
      "dysenterica    1\n",
      "lacrymans      1\n",
      "crespignyi     1\n",
      "klugii         1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Create dataframes for train and validation sets\n",
    "train_df = create_dataframe(train_path)\n",
    "valid_df = create_dataframe(valid_path)\n",
    "\n",
    "# Combine into a single dataframe with a 'is_valid' column for splitting\n",
    "df = pd.concat([\n",
    "    train_df.assign(is_valid=False),\n",
    "    valid_df.assign(is_valid=True)\n",
    "], ignore_index=True)\n",
    "\n",
    "# Remove redundant subspecies\n",
    "df = remove_redundant_subspecies(df)\n",
    "\n",
    "# ----- Add these statistics printing sections -----\n",
    "\n",
    "# Print basic dataset statistics\n",
    "print(f\"Total images: {len(df)}\")\n",
    "print(f\"Training images: {len(df[~df['is_valid']])}\")\n",
    "print(f\"Validation images: {len(df[df['is_valid']])}\")\n",
    "\n",
    "# Expand the labels column into a list for analysis\n",
    "all_labels = []\n",
    "for label_str in df['labels']:\n",
    "    all_labels.extend(label_str)\n",
    "\n",
    "# Count unique labels\n",
    "unique_labels = pd.Series(all_labels).unique()\n",
    "print(f\"Total unique labels: {len(unique_labels)}\")\n",
    "print(f\"Species labels: {len([l for l in unique_labels if '_' not in l])}\")\n",
    "print(f\"Subspecies labels: {len([l for l in unique_labels if '_' in l])}\")\n",
    "\n",
    "# Show label distribution\n",
    "label_counts = pd.Series(all_labels).value_counts()\n",
    "print(\"\\nTop 10 most common labels:\")\n",
    "print(label_counts.head(10))\n",
    "print(\"\\nBottom 10 least common labels:\")\n",
    "print(label_counts.tail(10))\n",
    "\n",
    "# Print examples of labels for verification\n",
    "print(\"\\nSample of extracted labels for verification:\")\n",
    "sample_rows = df.sample(min(5, len(df)))\n",
    "for _, row in sample_rows.iterrows():\n",
    "    print(f\"Path: {row['path'].name}, Labels: {row['labels']}\")\n",
    "\n",
    "# Check for extreme cases - species with many or few images\n",
    "species_counts = pd.Series([l.split('_')[0] for l in all_labels]).value_counts()\n",
    "print(\"\\nSpecies with most images:\")\n",
    "print(species_counts.head(5))\n",
    "print(\"\\nSpecies with fewest images:\")\n",
    "print(species_counts.tail(5))\n",
    "\n",
    "# ----- End of statistics section -----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c42e719",
   "metadata": {},
   "source": [
    "## Single-Label DataBlock Configuration\n",
    "\n",
    "Configure the data processing pipeline for single-label training:\n",
    "\n",
    "- **CategoryBlock**: Uses single categorical labels (most specific taxonomic level)\n",
    "- **Image preprocessing**: Resize to 448px with padding to maintain aspect ratio\n",
    "- **Augmentation**: Geometric transformations (rotation, zoom, warp) and photometric changes (lighting)\n",
    "- **Normalization**: Uses ImageNet statistics for pretrained model compatibility\n",
    "\n",
    "Note: Although we plan to do multi-label learning, we first train a single-label model to establish good feature representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "daf850fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the DataBlock\n",
    "#dblock_sl = DataBlock(\n",
    "#    blocks=(ImageBlock, CategoryBlock),\n",
    "#    get_x=ColReader('path'),\n",
    "#    get_y=ColReader('labels'),\n",
    "#    splitter=ColSplitter('is_valid'),\n",
    "#    item_tfms=[Resize(int(resize_dim*1.5), method='pad', pad_mode='border'),\n",
    "#               DihedralItem(p=0.5)],\n",
    "#    batch_tfms=[\n",
    "#        *aug_transforms(do_flip=False, \n",
    "#                        max_rotate=45, \n",
    "#                        max_warp=0.1,\n",
    "#                        max_lighting=0.3, \n",
    "#                        min_zoom = 0.7,\n",
    "#                        max_zoom = 1,\n",
    "#                        p_lighting=0.2,\n",
    "#                        p_affine=0.2,\n",
    "#                        pad_mode='border'),\n",
    "#        RandomResizedCrop(size = resize_dim,min_scale=0.2, max_scale=2,p=0.7),\n",
    "#        Normalize.from_stats(*imagenet_stats, cuda=False)\n",
    "#    ]\n",
    "#)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83b4fc5-bbbf-47d6-b38b-8dcdfae82eb2",
   "metadata": {},
   "source": [
    "## Class Balancing Through Weighted Sampling\n",
    "\n",
    "Address severe class imbalance using weighted sampling:\n",
    "\n",
    "1. **Weight calculation**: Compute inverse frequency weights for each label using square root scaling to prevent extreme values\n",
    "2. **Sample weighting**: For multi-label samples, use the mean weight of constituent labels\n",
    "3. **Normalization**: Scale weights so the minimum weight equals 1.0\n",
    "\n",
    "This approach up-samples rare species/subspecies during training while down-sampling common ones, helping the model learn from all taxonomic groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "977bea11-f1aa-4565-9717-b5e4c5f4d23d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "repanda                        644\n",
      "punctulata                     642\n",
      "repanda_repanda                461\n",
      "sexguttata                     421\n",
      "formosa                        355\n",
      "                              ... \n",
      "carthagena_colossea              1\n",
      "tranquebarica_parallelonota      1\n",
      "parowana_wallisi                 1\n",
      "klugii                           1\n",
      "nigrocoerulea_bowditchi          1\n",
      "Name: count, Length: 248, dtype: int64\n",
      "Individual label weights:\n",
      "  repanda: 644 occurrences (weight: 1.000)\n",
      "  punctulata: 642 occurrences (weight: 1.002)\n",
      "  repanda_repanda: 461 occurrences (weight: 1.182)\n",
      "  sexguttata: 421 occurrences (weight: 1.237)\n",
      "  formosa: 355 occurrences (weight: 1.347)\n",
      "  scutellaris: 355 occurrences (weight: 1.347)\n",
      "  oregona: 343 occurrences (weight: 1.370)\n",
      "  oregona_oregona: 281 occurrences (weight: 1.514)\n",
      "  ocellata: 257 occurrences (weight: 1.583)\n",
      "  formosa_generosa: 245 occurrences (weight: 1.621)\n",
      "  tranquebarica: 245 occurrences (weight: 1.621)\n",
      "  trifasciata: 241 occurrences (weight: 1.635)\n",
      "  hirticollis: 226 occurrences (weight: 1.688)\n",
      "  punctulata_punctulata: 214 occurrences (weight: 1.735)\n",
      "  scutellaris_lecontei: 200 occurrences (weight: 1.794)\n",
      "  hemorrhagica: 191 occurrences (weight: 1.836)\n",
      "  hemorrhagica_hemorrhagica: 182 occurrences (weight: 1.881)\n",
      "  purpurea: 159 occurrences (weight: 2.013)\n",
      "  tranquebarica_tranquebarica: 149 occurrences (weight: 2.079)\n",
      "  ocellata_ocellata: 130 occurrences (weight: 2.226)\n",
      "  sedecimpunctata: 128 occurrences (weight: 2.243)\n",
      "  ocellata_rectilatera: 127 occurrences (weight: 2.252)\n",
      "  sedecimpunctata_sedecimpunctata: 117 occurrences (weight: 2.346)\n",
      "  campestris: 111 occurrences (weight: 2.409)\n",
      "  duodecimguttata: 110 occurrences (weight: 2.420)\n",
      "  rufiventris: 106 occurrences (weight: 2.465)\n",
      "  hirticollis_hirticollis: 99 occurrences (weight: 2.551)\n",
      "  splendida: 99 occurrences (weight: 2.551)\n",
      "  rufiventris_rufiventris: 99 occurrences (weight: 2.551)\n",
      "  formosa_formosa: 99 occurrences (weight: 2.551)\n",
      "  longilabris: 94 occurrences (weight: 2.617)\n",
      "  hybrida: 89 occurrences (weight: 2.690)\n",
      "  campestris_campestris: 88 occurrences (weight: 2.705)\n",
      "  obsoleta: 86 occurrences (weight: 2.736)\n",
      "  limbalis: 77 occurrences (weight: 2.892)\n",
      "  hirticollis_rhodensis: 72 occurrences (weight: 2.991)\n",
      "  trifasciata_ascendens: 72 occurrences (weight: 2.991)\n",
      "  fulgida: 62 occurrences (weight: 3.223)\n",
      "  scutellaris_scutellaris: 59 occurrences (weight: 3.304)\n",
      "  concolor: 56 occurrences (weight: 3.391)\n",
      "  depressula: 55 occurrences (weight: 3.422)\n",
      "  fulgida_fulgida: 54 occurrences (weight: 3.453)\n",
      "  scutellaris_rugifrons: 54 occurrences (weight: 3.453)\n",
      "  longilabris_perviridis: 54 occurrences (weight: 3.453)\n",
      "  willistoni: 54 occurrences (weight: 3.453)\n",
      "  tenuisignata: 49 occurrences (weight: 3.625)\n",
      "  bellissima: 46 occurrences (weight: 3.742)\n",
      "  willistoni_echo: 45 occurrences (weight: 3.783)\n",
      "  latesignata: 43 occurrences (weight: 3.870)\n",
      "  tranquebarica_vibex: 43 occurrences (weight: 3.870)\n",
      "  lacrymosa: 42 occurrences (weight: 3.916)\n",
      "  trifasciata_sigmoidea: 41 occurrences (weight: 3.963)\n",
      "  chinensis: 39 occurrences (weight: 4.064)\n",
      "  nigrocoerulea: 37 occurrences (weight: 4.172)\n",
      "  nigrocoerulea_nigrocoerulea: 36 occurrences (weight: 4.230)\n",
      "  lengi: 35 occurrences (weight: 4.290)\n",
      "  purpurea_purpurea: 34 occurrences (weight: 4.352)\n",
      "  obsoleta_obsoleta: 33 occurrences (weight: 4.418)\n",
      "  sylvicola: 32 occurrences (weight: 4.486)\n",
      "  batesi: 31 occurrences (weight: 4.558)\n",
      "  lengi_lengi: 31 occurrences (weight: 4.558)\n",
      "  sylvatica: 31 occurrences (weight: 4.558)\n",
      "  decemguttata: 29 occurrences (weight: 4.712)\n",
      "  aurulenta: 28 occurrences (weight: 4.796)\n",
      "  oregona_guttifera: 28 occurrences (weight: 4.796)\n",
      "  hirticollis_shelfordi: 28 occurrences (weight: 4.796)\n",
      "  abdominalis: 27 occurrences (weight: 4.884)\n",
      "  sylvatica_sylvatica: 27 occurrences (weight: 4.884)\n",
      "  nebraskana: 27 occurrences (weight: 4.884)\n",
      "  carthagena: 26 occurrences (weight: 4.977)\n",
      "  limbata: 25 occurrences (weight: 5.075)\n",
      "  carthagena_carthagena: 25 occurrences (weight: 5.075)\n",
      "  purpurea_audubonii: 24 occurrences (weight: 5.180)\n",
      "  lunulata: 23 occurrences (weight: 5.292)\n",
      "  hybrida_hybrida: 23 occurrences (weight: 5.292)\n",
      "  quadripunctulata: 22 occurrences (weight: 5.410)\n",
      "  decemguttata_durvillei: 22 occurrences (weight: 5.410)\n",
      "  oregona_maricopa: 20 occurrences (weight: 5.675)\n",
      "  pulchra: 19 occurrences (weight: 5.822)\n",
      "  ancocisconensis: 19 occurrences (weight: 5.822)\n",
      "  scutellaris_rugata: 19 occurrences (weight: 5.822)\n",
      "  longilabris_longilabris: 19 occurrences (weight: 5.822)\n",
      "  trifasciata_trifasciata: 18 occurrences (weight: 5.981)\n",
      "  sexpunctata: 18 occurrences (weight: 5.981)\n",
      "  trifasciata_peruviana: 16 occurrences (weight: 6.344)\n",
      "  limbata_nympha: 15 occurrences (weight: 6.552)\n",
      "  obsoleta_vulturina: 15 occurrences (weight: 6.552)\n",
      "  sommeri: 14 occurrences (weight: 6.782)\n",
      "  gallica: 14 occurrences (weight: 6.782)\n",
      "  longilabris_laurentii: 14 occurrences (weight: 6.782)\n",
      "  theatina: 13 occurrences (weight: 7.038)\n",
      "  cyaniventris: 13 occurrences (weight: 7.038)\n",
      "  angulata: 12 occurrences (weight: 7.326)\n",
      "  angulata_angulata: 11 occurrences (weight: 7.652)\n",
      "  scutellaris_lecontei_x_Cicindela_(Cicindela)_scutellaris_scutellaris: 11 occurrences (weight: 7.652)\n",
      "  depressula_depressula: 10 occurrences (weight: 8.025)\n",
      "  soluta: 10 occurrences (weight: 8.025)\n",
      "  hirticollis_siuslawensis: 10 occurrences (weight: 8.025)\n",
      "  plutonica: 10 occurrences (weight: 8.025)\n",
      "  denverensis: 10 occurrences (weight: 8.025)\n",
      "  cincta: 10 occurrences (weight: 8.025)\n",
      "  setosomalaris: 9 occurrences (weight: 8.459)\n",
      "  maritima: 9 occurrences (weight: 8.459)\n",
      "  equestris: 9 occurrences (weight: 8.459)\n",
      "  duponti: 9 occurrences (weight: 8.459)\n",
      "  littoralis: 9 occurrences (weight: 8.459)\n",
      "  purpurea_cimarrona: 9 occurrences (weight: 8.459)\n",
      "  limbata_limbata: 9 occurrences (weight: 8.459)\n",
      "  hirticollis_gravida: 9 occurrences (weight: 8.459)\n",
      "  hemorrhagica_arizonae: 9 occurrences (weight: 8.459)\n",
      "  fischeri: 8 occurrences (weight: 8.972)\n",
      "  whithillii: 7 occurrences (weight: 9.592)\n",
      "  decemguttata_decemguttata: 7 occurrences (weight: 9.592)\n",
      "  sedecimpunctata_nigroconfluens: 7 occurrences (weight: 9.592)\n",
      "  senilis: 7 occurrences (weight: 9.592)\n",
      "  papillosa: 7 occurrences (weight: 9.592)\n",
      "  decemnotata: 7 occurrences (weight: 9.592)\n",
      "  scutellaris_unicolor: 7 occurrences (weight: 9.592)\n",
      "  rufiventris_heutzii: 7 occurrences (weight: 9.592)\n",
      "  hirticollis_corpuscula: 6 occurrences (weight: 10.360)\n",
      "  miseranda: 6 occurrences (weight: 10.360)\n",
      "  parowana: 6 occurrences (weight: 10.360)\n",
      "  virgula: 6 occurrences (weight: 10.360)\n",
      "  marginipennis: 6 occurrences (weight: 10.360)\n",
      "  hydrophoba: 6 occurrences (weight: 10.360)\n",
      "  obsoleta_santeclarae: 6 occurrences (weight: 10.360)\n",
      "  amargosae: 6 occurrences (weight: 10.360)\n",
      "  sachalinensis: 6 occurrences (weight: 10.360)\n",
      "  fischeri_elongatosignata: 5 occurrences (weight: 11.349)\n",
      "  lurida: 5 occurrences (weight: 11.349)\n",
      "  japana: 5 occurrences (weight: 11.349)\n",
      "  fulgida_westbournei: 5 occurrences (weight: 11.349)\n",
      "  fimbriata: 5 occurrences (weight: 11.349)\n",
      "  luteolineata: 5 occurrences (weight: 11.349)\n",
      "  hamiltoniana: 5 occurrences (weight: 11.349)\n",
      "  hornii: 5 occurrences (weight: 11.349)\n",
      "  tranquebarica_kirbyi: 5 occurrences (weight: 11.349)\n",
      "  arenicola: 5 occurrences (weight: 11.349)\n",
      "  interrupta: 5 occurrences (weight: 11.349)\n",
      "  rugatilis: 5 occurrences (weight: 11.349)\n",
      "  parowana_parowana: 5 occurrences (weight: 11.349)\n",
      "  tranquebarica_diffracta: 5 occurrences (weight: 11.349)\n",
      "  formosa_gibsoni: 5 occurrences (weight: 11.349)\n",
      "  clarina: 5 occurrences (weight: 11.349)\n",
      "  compressicornis: 5 occurrences (weight: 11.349)\n",
      "  littoralis_nemoralis: 5 occurrences (weight: 11.349)\n",
      "  vasseletii: 5 occurrences (weight: 11.349)\n",
      "  schauppii: 5 occurrences (weight: 11.349)\n",
      "  willistoni_willistoni: 4 occurrences (weight: 12.689)\n",
      "  granulata: 4 occurrences (weight: 12.689)\n",
      "  willistoni_pseudosenilis: 4 occurrences (weight: 12.689)\n",
      "  waynei: 4 occurrences (weight: 12.689)\n",
      "  sedecimpunctata_sallei: 4 occurrences (weight: 12.689)\n",
      "  cardoni: 4 occurrences (weight: 12.689)\n",
      "  heros: 4 occurrences (weight: 12.689)\n",
      "  transbaicalica: 4 occurrences (weight: 12.689)\n",
      "  turkestanica: 4 occurrences (weight: 12.689)\n",
      "  rufoaenea: 4 occurrences (weight: 12.689)\n",
      "  sanguineomaculata: 4 occurrences (weight: 12.689)\n",
      "  aulica: 4 occurrences (weight: 12.689)\n",
      "  denikei: 4 occurrences (weight: 12.689)\n",
      "  aeneicollis: 4 occurrences (weight: 12.689)\n",
      "  lengi_versuta: 4 occurrences (weight: 12.689)\n",
      "  nebuligera: 3 occurrences (weight: 14.652)\n",
      "  flohri: 3 occurrences (weight: 14.652)\n",
      "  varians: 3 occurrences (weight: 14.652)\n",
      "  caucasica: 3 occurrences (weight: 14.652)\n",
      "  fischeri_fischeri: 3 occurrences (weight: 14.652)\n",
      "  lugens: 3 occurrences (weight: 14.652)\n",
      "  tenuicincta: 3 occurrences (weight: 14.652)\n",
      "  scutellaris_flavoviridis: 3 occurrences (weight: 14.652)\n",
      "  alboguttata: 3 occurrences (weight: 14.652)\n",
      "  plumigera: 3 occurrences (weight: 14.652)\n",
      "  funerea: 3 occurrences (weight: 14.652)\n",
      "  depressula_eureka: 3 occurrences (weight: 14.652)\n",
      "  fimbriata_fimbriata: 3 occurrences (weight: 14.652)\n",
      "  chinensis_flammifera: 2 occurrences (weight: 17.944)\n",
      "  albissima: 2 occurrences (weight: 17.944)\n",
      "  fera: 2 occurrences (weight: 17.944)\n",
      "  lacteola: 2 occurrences (weight: 17.944)\n",
      "  formosa_pigmentosignata: 2 occurrences (weight: 17.944)\n",
      "  nysa: 2 occurrences (weight: 17.944)\n",
      "  maroccana: 2 occurrences (weight: 17.944)\n",
      "  favergeri: 2 occurrences (weight: 17.944)\n",
      "  politula: 2 occurrences (weight: 17.944)\n",
      "  octonotata: 2 occurrences (weight: 17.944)\n",
      "  scutellaris_yampae: 2 occurrences (weight: 17.944)\n",
      "  hirticollis_couleensis: 2 occurrences (weight: 17.944)\n",
      "  repanda_tanneri: 2 occurrences (weight: 17.944)\n",
      "  oregona_guttifera_x_(Cicindela)_oregona_navajoensis: 2 occurrences (weight: 17.944)\n",
      "  semicircularis: 2 occurrences (weight: 17.944)\n",
      "  lugens_lugens: 2 occurrences (weight: 17.944)\n",
      "  radians: 2 occurrences (weight: 17.944)\n",
      "  hybrida_pseudoriparia: 2 occurrences (weight: 17.944)\n",
      "  ismenia: 2 occurrences (weight: 17.944)\n",
      "  transbaicalica_hamifasciata: 2 occurrences (weight: 17.944)\n",
      "  fimbriata_imperatrix: 2 occurrences (weight: 17.944)\n",
      "  roseiventris: 2 occurrences (weight: 17.944)\n",
      "  aurofasciata: 2 occurrences (weight: 17.944)\n",
      "  hybrida_transversalis: 2 occurrences (weight: 17.944)\n",
      "  hydrophoba_quinquenotata: 2 occurrences (weight: 17.944)\n",
      "  chrysippe: 2 occurrences (weight: 17.944)\n",
      "  sylvatica_fasciatopunctata: 2 occurrences (weight: 17.944)\n",
      "  coerulea: 2 occurrences (weight: 17.944)\n",
      "  funerea_assimilis: 2 occurrences (weight: 17.944)\n",
      "  neumanni: 2 occurrences (weight: 17.944)\n",
      "  restricta: 2 occurrences (weight: 17.944)\n",
      "  gemmata: 2 occurrences (weight: 17.944)\n",
      "  altaica: 2 occurrences (weight: 17.944)\n",
      "  pugetana: 2 occurrences (weight: 17.944)\n",
      "  fulgida_rumppi: 2 occurrences (weight: 17.944)\n",
      "  tranquebarica_sierra: 2 occurrences (weight: 17.944)\n",
      "  pimeriana: 2 occurrences (weight: 17.944)\n",
      "  turkestanica_turkestanica: 2 occurrences (weight: 17.944)\n",
      "  scabrosa: 2 occurrences (weight: 17.944)\n",
      "  oregona_navajoensis: 2 occurrences (weight: 17.944)\n",
      "  campestris_suffriani: 2 occurrences (weight: 17.944)\n",
      "  hydrophoba_tarentana: 2 occurrences (weight: 17.944)\n",
      "  clypeata: 2 occurrences (weight: 17.944)\n",
      "  turkestanica_gissariensis: 2 occurrences (weight: 17.944)\n",
      "  sturmi: 2 occurrences (weight: 17.944)\n",
      "  campestris_pontica: 2 occurrences (weight: 17.944)\n",
      "  columbica: 1 occurrences (weight: 25.377)\n",
      "  hybrida_magyarica: 1 occurrences (weight: 25.377)\n",
      "  macrochila: 1 occurrences (weight: 25.377)\n",
      "  princeps: 1 occurrences (weight: 25.377)\n",
      "  funerea_funerea: 1 occurrences (weight: 25.377)\n",
      "  asperula: 1 occurrences (weight: 25.377)\n",
      "  limbata_hyperborea: 1 occurrences (weight: 25.377)\n",
      "  bicolor: 1 occurrences (weight: 25.377)\n",
      "  chinensis_japonica: 1 occurrences (weight: 25.377)\n",
      "  calligrama: 1 occurrences (weight: 25.377)\n",
      "  repanda_novascotiae: 1 occurrences (weight: 25.377)\n",
      "  willistoni_praedicta: 1 occurrences (weight: 25.377)\n",
      "  campestris_olivieria: 1 occurrences (weight: 25.377)\n",
      "  desertorum: 1 occurrences (weight: 25.377)\n",
      "  carissima: 1 occurrences (weight: 25.377)\n",
      "  pulchra_dorothea: 1 occurrences (weight: 25.377)\n",
      "  dysenterica: 1 occurrences (weight: 25.377)\n",
      "  hydrophoba_atroreducta: 1 occurrences (weight: 25.377)\n",
      "  crespignyi: 1 occurrences (weight: 25.377)\n",
      "  lugens_aphrodisia: 1 occurrences (weight: 25.377)\n",
      "  lacrymans: 1 occurrences (weight: 25.377)\n",
      "  carthagena_colossea: 1 occurrences (weight: 25.377)\n",
      "  tranquebarica_parallelonota: 1 occurrences (weight: 25.377)\n",
      "  parowana_wallisi: 1 occurrences (weight: 25.377)\n",
      "  klugii: 1 occurrences (weight: 25.377)\n",
      "  nigrocoerulea_bowditchi: 1 occurrences (weight: 25.377)\n",
      "\n",
      "Sample weight stats:\n",
      "  Min: 1.000\n",
      "  Max: 25.377\n",
      "  Mean: 2.911\n",
      "  Number of weights: 4883\n"
     ]
    }
   ],
   "source": [
    "# Calculate multilabel-aware weights\n",
    "def calculate_multilabel_weights_for_weighted_dl(df):\n",
    "    # Get training data only\n",
    "    train_df = df[df['is_valid'] == False].copy()\n",
    "    \n",
    "    # Count frequency of each individual label across all samples\n",
    "    all_labels = []\n",
    "    for label_list in train_df['labels']:\n",
    "        for label in label_list:\n",
    "            if label == 'a':\n",
    "                print(label_list)\n",
    "                break\n",
    "        all_labels.extend(label_list)\n",
    "        \n",
    "    \n",
    "    print(\"a\" in all_labels)\n",
    "    print(label_counts)\n",
    "    total_samples = len(train_df)\n",
    "    \n",
    "    # Calculate inverse frequency weights for each label\n",
    "    label_weights = {}\n",
    "    for label, count in label_counts.items():\n",
    "        label_weights[label] = np.sqrt(total_samples / count)\n",
    "    \n",
    "    # Normalize weights to prevent extreme values\n",
    "    min_weight = min(label_weights.values())\n",
    "    label_weights = {k: v/min_weight for k, v in label_weights.items()}\n",
    "    \n",
    "    print(\"Individual label weights:\")\n",
    "    for label, weight in sorted(label_weights.items(), key=lambda x: x[1]):\n",
    "        count = label_counts[label]\n",
    "        print(f\"  {label}: {count} occurrences (weight: {weight:.3f})\")\n",
    "    \n",
    "    # Calculate sample weights (mean of constituent label weights)\n",
    "    sample_weights = []\n",
    "    for label_list in train_df['labels']:\n",
    "        sample_label_weights = [label_weights[label] for label in label_list]\n",
    "        sample_weight = np.mean(sample_label_weights)\n",
    "        sample_weights.append(sample_weight)\n",
    "    \n",
    "    print(f\"\\nSample weight stats:\")\n",
    "    print(f\"  Min: {min(sample_weights):.3f}\")\n",
    "    print(f\"  Max: {max(sample_weights):.3f}\")\n",
    "    print(f\"  Mean: {np.mean(sample_weights):.3f}\")\n",
    "    print(f\"  Number of weights: {len(sample_weights)}\")\n",
    "    \n",
    "    return sample_weights\n",
    "\n",
    "# Calculate weights based on original multilabel data\n",
    "sample_weights = calculate_multilabel_weights_for_weighted_dl(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc65801d-04ee-41c2-a57a-627bd8422d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the processed dataframe for single-label training\n",
    "df_processed = df.assign(labels=df['labels'].apply(lambda x: '_'.join(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15a0b218-b84f-4e39-8355-d558c84d22e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create CPU-only dataloaders for visualization and batch inspection\n",
    "#dls_cpu = dblock_sl.dataloaders(\n",
    "#    df_processed,\n",
    "#    bs=batch_size,\n",
    "#    num_workers=0,  # CPU only\n",
    "#    device='cpu'\n",
    "#)\n",
    "\n",
    "#print(f\"\\nCreated CPU dataloaders for visualization with {len(df_processed[~df_processed['is_valid']])} training samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae7517d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a batch of training images with their labels\n",
    "#dls_cpu.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf220cb4",
   "metadata": {},
   "source": [
    "## Single-Label Model Training with Distributed Data Parallel\n",
    "\n",
    "Create a distributed training function that uses fastai's `distrib_ctx()` for multi-GPU training:\n",
    "\n",
    "1. **Distributed setup**: Use `distrib_ctx()` to enable distributed data parallel training\n",
    "2. **Architecture**: Vision transformer (EVA02-Large) pretrained on ImageNet  \n",
    "3. **Optimization**: Mixed precision training (`to_fp16()`) for efficiency\n",
    "4. **Regularization**: MixUp augmentation to improve generalization\n",
    "5. **Metrics**: Standard accuracy and balanced accuracy to handle class imbalance\n",
    "\n",
    "This approach automatically handles multi-GPU coordination and gradient synchronization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd8d9c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching training on 4 GPUs.\n",
      "Training Learner...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bdemedeiros/software/miniconda3/envs/fastai/lib/python3.11/site-packages/fastai/callback/fp16.py:47: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  self.autocast,self.learn.scaler,self.scales = autocast(dtype=dtype),GradScaler(**self.kwargs),L()\n",
      "/home/bdemedeiros/software/miniconda3/envs/fastai/lib/python3.11/site-packages/fastai/callback/fp16.py:47: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.autocast,self.learn.scaler,self.scales = autocast(dtype=dtype),GradScaler(**self.kwargs),L()\n",
      "/home/bdemedeiros/software/miniconda3/envs/fastai/lib/python3.11/site-packages/fastai/callback/fp16.py:47: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  self.autocast,self.learn.scaler,self.scales = autocast(dtype=dtype),GradScaler(**self.kwargs),L()\n",
      "/home/bdemedeiros/software/miniconda3/envs/fastai/lib/python3.11/site-packages/fastai/callback/fp16.py:47: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.autocast,self.learn.scaler,self.scales = autocast(dtype=dtype),GradScaler(**self.kwargs),L()\n",
      "/home/bdemedeiros/software/miniconda3/envs/fastai/lib/python3.11/site-packages/fastai/callback/fp16.py:47: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  self.autocast,self.learn.scaler,self.scales = autocast(dtype=dtype),GradScaler(**self.kwargs),L()\n",
      "/home/bdemedeiros/software/miniconda3/envs/fastai/lib/python3.11/site-packages/fastai/callback/fp16.py:47: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.autocast,self.learn.scaler,self.scales = autocast(dtype=dtype),GradScaler(**self.kwargs),L()\n",
      "/home/bdemedeiros/software/miniconda3/envs/fastai/lib/python3.11/site-packages/fastai/callback/fp16.py:47: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  self.autocast,self.learn.scaler,self.scales = autocast(dtype=dtype),GradScaler(**self.kwargs),L()\n",
      "/home/bdemedeiros/software/miniconda3/envs/fastai/lib/python3.11/site-packages/fastai/callback/fp16.py:47: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.autocast,self.learn.scaler,self.scales = autocast(dtype=dtype),GradScaler(**self.kwargs),L()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00&lt;?]\n",
       "    </div>\n",
       "    \n",
       "\n",
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='153' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/153 00:00&lt;?]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def train_single_label(df_processed, \n",
    "                       sample_weights, \n",
    "                       resize_dim, \n",
    "                       batch_size,\n",
    "                       n_workers,\n",
    "                       p_memory,\n",
    "                       \n",
    "                       arch):\n",
    "    \n",
    "    class DistributedNormalize(Normalize):\n",
    "        \"\"\"FastAI Normalize class fixed for distributed training\"\"\"\n",
    "        def encodes(self, x: TensorImage):\n",
    "            # Move mean and std to the same device as input tensor\n",
    "            device = x.device\n",
    "            mean = self.mean.to(device) if self.mean.device != device else self.mean\n",
    "            std = self.std.to(device) if self.std.device != device else self.std\n",
    "            return (x - mean) / std\n",
    "\n",
    "    \n",
    "    # DataBlock with manual normalization\n",
    "    dblock_sl = DataBlock(\n",
    "        blocks=(ImageBlock, CategoryBlock),\n",
    "        get_x=ColReader('path'),\n",
    "        get_y=ColReader('labels'),\n",
    "        splitter=ColSplitter('is_valid'),\n",
    "        item_tfms=[\n",
    "            Resize(int(resize_dim*1.5), method='pad', pad_mode='border'),\n",
    "            DihedralItem(p=0.5)\n",
    "        ],\n",
    "        batch_tfms=[\n",
    "            *aug_transforms(\n",
    "                do_flip=False, \n",
    "                max_rotate=45, \n",
    "                max_warp=0.1,\n",
    "                max_lighting=0.3, \n",
    "                min_zoom=0.7,\n",
    "                max_zoom=1,\n",
    "                p_lighting=0.2,\n",
    "                p_affine=0.2,\n",
    "                pad_mode='border'\n",
    "            ),\n",
    "            RandomResizedCropGPU(size=resize_dim, min_scale=0.2, max_scale=2, p=0.7),\n",
    "            DistributedNormalize.from_stats(\n",
    "    mean=[0.485, 0.456, 0.406],\n",
    "    std=[0.229, 0.224, 0.225]\n",
    ") \n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    dls_sl = dblock_sl.weighted_dataloaders(\n",
    "        df_processed,\n",
    "        wgts=sample_weights,\n",
    "        bs=batch_size,\n",
    "        num_workers=n_workers,\n",
    "        pin_memory=p_memory,\n",
    "        persistent_workers=p_workers,\n",
    "        prefetch_factor=6,\n",
    "        drop_last=True\n",
    "    )\n",
    "    \n",
    "    # Create learner \n",
    "    learn_sl = vision_learner(\n",
    "        dls_sl, \n",
    "        arch,\n",
    "        metrics=[accuracy, BalancedAccuracy()],\n",
    "        normalize=False, \n",
    "        cbs=[MixUp()]\n",
    "    ).to_fp16()\n",
    "    \n",
    "    with learn_sl.distrib_ctx(in_notebook=True, sync_bn=True):\n",
    "        learn_sl.freeze()\n",
    "        base_lr = learn_sl.lr_find()\n",
    "        learn_sl.fine_tune(epochs=5, freeze_epochs=5, base_lr=base_lr.valley)\n",
    "    \n",
    "    learn_sl.export(f\"model_fixed_{arch}.pkl\")\n",
    "    return learn_sl\n",
    "    \n",
    "# Run it\n",
    "notebook_launcher(train_single_label, (df_processed, sample_weights, resize_dim, batch_size, n_workers, p_memory, arch), num_processes=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb5aed2-869e-4dbc-870c-2fa935773a6a",
   "metadata": {},
   "source": [
    "## Multi-Label Model Setup and Transfer Learning with Distributed Training\n",
    "\n",
    "Configure and initialize the multi-label model with distributed data parallel:\n",
    "\n",
    "1. **Architecture change**: Switch from CategoryBlock to MultiCategoryBlock for multi-label classification\n",
    "2. **Loss function**: Use AsymmetricLossMultiLabel optimized for imbalanced multi-label problems\n",
    "3. **Metrics**: Micro-averaged precision, recall, and ROC-AUC for multi-label evaluation\n",
    "4. **Transfer learning**: Load compatible weights from the single-label model to initialize features\n",
    "5. **Weight filtering**: Only transfer layers with matching dimensions between models\n",
    "6. **Distributed training**: Use `distrib_ctx()` for multi-GPU coordination\n",
    "\n",
    "This leverages the hierarchical features learned in single-label training for multi-label prediction."
   ]
  },
  {
   "cell_type": "code",
   "id": "86176f12-aad2-476a-9d92-1b20ce2c6f22",
   "metadata": {},
   "outputs": [],
   "source": "def train_multi_label(df, \n                      sample_weights, \n                      resize_dim, \n                      batch_size,\n                      n_workers,\n                      p_memory,\n                      arch):\n    \"\"\"Distributed training function for multi-label model\"\"\"\n    \n    class DistributedNormalize(Normalize):\n        \"\"\"FastAI Normalize class fixed for distributed training\"\"\"\n        def encodes(self, x: TensorImage):\n            # Move mean and std to the same device as input tensor\n            device = x.device\n            mean = self.mean.to(device) if self.mean.device != device else self.mean\n            std = self.std.to(device) if self.std.device != device else self.std\n            return (x - mean) / std\n    \n    # Define the multi-label DataBlock inside the function\n    dblock_ml = DataBlock(\n        blocks=(ImageBlock, MultiCategoryBlock),\n        get_x=ColReader('path'),\n        get_y=ColReader('labels'),\n        splitter=ColSplitter('is_valid'),\n        item_tfms=[\n            Resize(int(resize_dim*1.5), method='pad', pad_mode='border'),\n            DihedralItem(p=0.5)\n        ],\n        batch_tfms=[\n            *aug_transforms(\n                do_flip=False, \n                max_rotate=45, \n                max_warp=0.1,\n                max_lighting=0.3, \n                min_zoom=0.7,\n                max_zoom=1,\n                p_lighting=0.2,\n                p_affine=0.2,\n                pad_mode='border'\n            ),\n            RandomResizedCropGPU(size=resize_dim, min_scale=0.2, max_scale=2, p=0.7),\n            DistributedNormalize.from_stats(\n                mean=[0.485, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225]\n            )\n        ]\n    )\n\n    # Create weighted dataloaders inside the training function\n    dls_ml = dblock_ml.weighted_dataloaders(\n        df, \n        wgts=sample_weights,\n        bs=batch_size, \n        num_workers=n_workers,\n        pin_memory=p_memory,\n        persistent_workers=p_workers,\n        prefetch_factor=6,\n        drop_last=True\n    )\n\n    # Create learner\n    learn_ml = vision_learner(\n        dls_ml, \n        arch,\n        metrics=[PrecisionMulti(average='micro', thresh=0.5),\n                RecallMulti(average='micro', thresh=0.5),\n                RocAuc(average='micro')],\n        loss_func=AsymmetricLossMultiLabel(gamma_neg=2,\n                                          gamma_pos=2,\n                                          clip=0.05),\n        normalize=False,\n        cbs=[MixUp()]\n    ).to_fp16()\n\n    # Transfer weights from single-label model\n    learn_sl = load_learner(f\"model_fixed_{arch}.pkl\").detach_parallel()\n    source_state_dict = learn_sl.model.state_dict()\n    target_state_dict = learn_ml.model.state_dict()\n\n    # Only load layers with matching shapes\n    filtered_state_dict = {}\n    for k, v in source_state_dict.items():\n        if k in target_state_dict and target_state_dict[k].shape == v.shape:\n            filtered_state_dict[k] = v\n\n    learn_ml.model.load_state_dict(filtered_state_dict, strict=False)\n\n    # Clean up single-label model\n    del(learn_sl)\n    gc.collect()\n    torch.cuda.empty_cache()\n\n    # Use distributed context manager for multi-GPU training\n    with learn_ml.distrib_ctx(in_notebook=True, sync_bn=True):\n        # Freeze the pretrained layers\n        learn_ml.freeze()\n\n        # Find optimal learning rate\n        base_lr = learn_ml.lr_find()\n\n        # Fine-tune the model\n        learn_ml.fine_tune(epochs=10, freeze_epochs=3, base_lr=base_lr.valley)\n\n    # Export the model after distributed training completes\n    learn_ml.export(export_path/f\"{arch}_ml.pkl\")\n    return learn_ml\n\n# Launch distributed training for multi-label model with consistent parameters\nnotebook_launcher(train_multi_label, (df, sample_weights, resize_dim, batch_size, n_workers, p_memory, arch), num_processes=4)"
  },
  {
   "cell_type": "markdown",
   "id": "7e4e2b7b-f182-4e77-b01f-fd6e3bfbf94f",
   "metadata": {},
   "source": "## Multi-Label Model Training Complete\n\nThe multi-label model training is now complete and handled entirely within the distributed training function above. The model has been exported and is ready for evaluation.",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "98043591-e901-4c90-ba9b-5ec6444f0119",
   "metadata": {},
   "source": [
    "## Test Set Evaluation\n",
    "\n",
    "Evaluate the final model on the held-out test set:\n",
    "\n",
    "1. **Model loading**: Load the trained multi-label model\n",
    "2. **Test data preparation**: Process test images with same preprocessing pipeline\n",
    "3. **Vocabulary filtering**: Ensure test labels match the model's vocabulary\n",
    "4. **Test dataloader**: Create dataloader for test set with labels for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcf14d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = load_learner(export_path/f\"{arch}_ml.pkl\", cpu=False)\n",
    "\n",
    "test_df = create_dataframe(test_path)\n",
    "\n",
    "vocab_list = learn.dls.vocab\n",
    "def filter_labels(label_list, vocab):\n",
    "    return [label for label in label_list if label in vocab]\n",
    "test_df['labels'] = test_df['labels'].apply(lambda x: filter_labels(x, vocab_list))\n",
    "test_df['is_valid'] = True\n",
    "\n",
    "test_dl = learn.dls.test_dl(test_df, with_labels = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8b37ce",
   "metadata": {},
   "source": [
    "## Model Predictions\n",
    "\n",
    "Generate predictions on the test set for detailed analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a4b65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions and targets\n",
    "preds, targs = learn.get_preds(dl = test_dl, with_loss=False, with_targs=True, act = torch.sigmoid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548e8d4a-ffd4-4dc3-bef2-c6cdd4c42bb8",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Detailed Performance Analysis by Taxonomic Class\n",
    "\n",
    "Calculate comprehensive evaluation metrics for each taxonomic class:\n",
    "\n",
    "1. **Binary classification metrics**: Convert multi-label predictions to binary decisions using 0.5 threshold\n",
    "2. **Per-class evaluation**: Calculate precision, recall, true/false positives/negatives for each class\n",
    "3. **Training set mapping**: Include training set counts to understand data availability\n",
    "4. **Confusion analysis**: Identify which classes are commonly confused with each other\n",
    "5. **Results formatting**: Create publication-ready table with performance metrics\n",
    "\n",
    "This analysis reveals model performance across the taxonomic hierarchy and identifies challenging classification cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf33503-4b1c-4b0f-92eb-5ed58d036330",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_threshold = 0.5\n",
    "# Get vocabulary\n",
    "vocab = learn.dls.vocab\n",
    "if isinstance(vocab, list):\n",
    "    vocab = vocab[-1]  # As in ClassificationInterpretation.__init__\n",
    "\n",
    "# Get training set counts for each term from train_df\n",
    "train_counts = {}\n",
    "\n",
    "# Initialize counts for all classes\n",
    "for i in range(len(vocab)):\n",
    "    train_counts[i] = 0\n",
    "\n",
    "# Count occurrences in training DataFrame\n",
    "for labels_list in train_df['labels']:\n",
    "    # Convert string representation to actual list if needed\n",
    "    if isinstance(labels_list, str):\n",
    "        # Remove brackets and quotes, then split\n",
    "        labels_list = labels_list.strip('[]').replace(\"'\", \"\").split(', ')\n",
    "    \n",
    "    # Count each label\n",
    "    for label in labels_list:\n",
    "        label = label.strip()  # Remove any whitespace\n",
    "        # Use vocab.o2i to get the index instead of .index()\n",
    "        if hasattr(vocab, 'o2i') and label in vocab.o2i:\n",
    "            idx = vocab.o2i[label]\n",
    "            train_counts[idx] += 1\n",
    "        elif label in vocab:\n",
    "            # Fallback if o2i doesn't exist\n",
    "            for i, v in enumerate(vocab):\n",
    "                if v == label:\n",
    "                    train_counts[i] += 1\n",
    "                    break\n",
    "\n",
    "# Determine if this is multi-label or multi-class\n",
    "is_multilabel = len(targs.shape) > 1\n",
    "\n",
    "# Convert tensors to numpy\n",
    "preds_np = preds.cpu().numpy()\n",
    "targs_np = targs.cpu().numpy()\n",
    "\n",
    "# For multi-label, threshold predictions\n",
    "if is_multilabel:\n",
    "    preds_binary = (preds_np > pred_threshold).astype(int)\n",
    "else:\n",
    "    # For multi-class, convert to one-hot encoding\n",
    "    preds_binary = np.zeros_like(preds_np)\n",
    "    for i in range(len(preds_np)):\n",
    "        preds_binary[i, np.argmax(preds_np[i])] = 1\n",
    "\n",
    "# Dictionary to track confusions\n",
    "confusions = defaultdict(list)\n",
    "\n",
    "# Calculate confusions - for each sample, identify false positives when true labels are present\n",
    "for i in range(len(targs_np)):\n",
    "    if is_multilabel:\n",
    "        # For each sample, get true labels and predicted labels\n",
    "        true_labels = np.where(targs_np[i] == 1)[0]\n",
    "        pred_labels = np.where(preds_binary[i] == 1)[0]\n",
    "        \n",
    "        # For each true label, find false positives\n",
    "        for true_idx in true_labels:\n",
    "            false_pos_indices = [idx for idx in pred_labels if idx != true_idx and idx not in true_labels]\n",
    "            if false_pos_indices:  # If there are false positives\n",
    "                confusions[true_idx].extend(false_pos_indices)\n",
    "    else:\n",
    "        # For multi-class, the true label is confused with the predicted label if they differ\n",
    "        true_label = np.argmax(targs_np[i]) if len(targs_np.shape) > 1 else targs_np[i]\n",
    "        pred_label = np.argmax(preds_np[i])\n",
    "        if true_label != pred_label:\n",
    "            confusions[true_label].append(pred_label)\n",
    "\n",
    "# Create a list to store results\n",
    "results = []\n",
    "\n",
    "# Calculate metrics for each class\n",
    "for i in range(preds.shape[1]):\n",
    "    # Get class name\n",
    "    if i < len(vocab):\n",
    "        class_name = vocab[i]\n",
    "    else:\n",
    "        class_name = f\"Class_{i}\"\n",
    "    \n",
    "    # Extract binary predictions and targets for this class\n",
    "    if is_multilabel:\n",
    "        pred_i = preds_binary[:, i]\n",
    "        targ_i = targs_np[:, i]\n",
    "    else:\n",
    "        # For multi-class, create one-hot encoding\n",
    "        pred_i = (np.argmax(preds_np, axis=1) == i).astype(int)\n",
    "        targ_i = (targs_np == i).astype(int) if len(targs_np.shape) == 1 else (np.argmax(targs_np, axis=1) == i).astype(int)\n",
    "    \n",
    "    # Calculate N (number of samples with this label in test/validation set)\n",
    "    N = targ_i.sum()\n",
    "    \n",
    "    # Get training count for this class\n",
    "    N_train = int(train_counts.get(i, 0))\n",
    "    \n",
    "    # Skip if N is zero\n",
    "    if N == 0:\n",
    "        continue\n",
    "    \n",
    "    # Calculate metrics\n",
    "    true_positives = np.sum((pred_i == 1) & (targ_i == 1))\n",
    "    false_positives = np.sum((pred_i == 1) & (targ_i == 0))\n",
    "    false_negatives = np.sum((pred_i == 0) & (targ_i == 1))\n",
    "    \n",
    "    precision = true_positives / (true_positives + false_positives) if true_positives + false_positives > 0 else 1\n",
    "    recall = true_positives / (true_positives + false_negatives) if true_positives + false_negatives > 0 else 0\n",
    "    \n",
    "    # Process confusions for this class\n",
    "    confused_with = []\n",
    "    if i in confusions and confusions[i]:\n",
    "        # Count occurrences of each confusion\n",
    "        confusion_counts = {}\n",
    "        for idx in confusions[i]:\n",
    "            if idx < len(vocab):\n",
    "                label = vocab[idx]\n",
    "                confusion_counts[label] = confusion_counts.get(label, 0) + 1\n",
    "            else:\n",
    "                label = f\"Class_{idx}\"\n",
    "                confusion_counts[label] = confusion_counts.get(label, 0) + 1\n",
    "        \n",
    "        # Sort by count and format as \"label (count)\"\n",
    "        confused_with = [f\"{label} ({count})\" for label, count in \n",
    "                         sorted(confusion_counts.items(), key=lambda x: x[1], reverse=True)]\n",
    "    \n",
    "    # Add to results\n",
    "    results.append({\n",
    "        'Term': class_name,\n",
    "        'N_train': N_train,\n",
    "        'N': int(N),\n",
    "        'micro_precision': precision,\n",
    "        'micro_recall': recall,\n",
    "        'true_positives': int(true_positives),\n",
    "        'false_positives': int(false_positives),\n",
    "        'false_negatives': int(false_negatives),\n",
    "        'confused_with': ', '.join(confused_with) if confused_with else ''\n",
    "    })\n",
    "\n",
    "# Create DataFrame and sort by micro_precision first, then by N (both descending)\n",
    "df = pd.DataFrame(results)\n",
    "df = df.sort_values(['micro_precision', 'N'], ascending=[False, False])\n",
    "\n",
    "# Format DataFrame for display\n",
    "pd.set_option('display.float_format', '{:.4f}'.format)  # Format floats to 4 decimal places\n",
    "\n",
    "# Format precision and recall as percentages\n",
    "df['micro_precision'] = df['micro_precision'] * 100\n",
    "df['micro_recall'] = df['micro_recall'] * 100\n",
    "\n",
    "# Create a styled version of the DataFrame\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Style the DataFrame\n",
    "styled_df = df.style.format({\n",
    "    'N_train': '{:,d}',\n",
    "    'N': '{:,d}',\n",
    "    'micro_precision': '{:.2f}%',\n",
    "    'micro_recall': '{:.2f}%',\n",
    "    'true_positives': '{:,d}',\n",
    "    'false_positives': '{:,d}',\n",
    "    'false_negatives': '{:,d}'\n",
    "}).background_gradient(subset=['micro_precision', 'micro_recall'], cmap='RdYlGn')\n",
    "\n",
    "# Add a title and display\n",
    "display(HTML(\"<h2>Model Performance by Term</h2>\"))\n",
    "display(styled_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748a30eb-866f-4dd0-a1a3-71db1db5c919",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(f\"test_results_{arch}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d678cd-3f71-441a-8c52-05b169921f2c",
   "metadata": {},
   "source": [
    "# Evaluation in unknown samples\n",
    "\n",
    "To finalize, let's try to identify the unknown samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efeb80ae-3899-4973-b6d4-2b705a8dc3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown_df = pd.DataFrame({'path':get_image_files('unknowns'),'labels':None,'is_valid':True})\n",
    "test_dl = learn.dls.test_dl(unknown_df, with_labels = False)\n",
    "unknown_preds, _ = learn.get_preds(dl = test_dl, with_loss=False, with_targs=False, act=torch.sigmoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e9cde7-25ca-4eef-b3ae-798b61f728e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert predictions to binary predictions\n",
    "binary_preds = (unknown_preds > 0.5).int()\n",
    "\n",
    "# Use fastai's decode method if available\n",
    "try:\n",
    "    pred_labels = [learn.dls.decode(row) for row in binary_preds]\n",
    "    unknown_df['predictions'] = pred_labels\n",
    "except:\n",
    "    # Fallback to manual method\n",
    "    pred_labels = []\n",
    "    for row in binary_preds:\n",
    "        indices = torch.nonzero(row, as_tuple=True)[0]\n",
    "        labels = [learn.dls.vocab[i] for i in indices.tolist()]\n",
    "        pred_labels.append(labels)\n",
    "    unknown_df['predictions'] = pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bdd609-6359-4e55-a9cb-878b1af95105",
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38fd023-6a6c-406d-bce5-ed284bce610a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}